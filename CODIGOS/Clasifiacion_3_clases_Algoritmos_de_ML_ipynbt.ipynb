{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jhonier29/Proyecto-Detecci-n-de-estr-s/blob/main/CODIGOS/Clasifiacion_3_clases_Algoritmos_de_ML_ipynbt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZPQuSL3ib_2"
      },
      "source": [
        "#Cargar Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2m8GDgcEj-l"
      },
      "outputs": [],
      "source": [
        "! pip install eli5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imM6hQ8UcvUq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow as tf\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.inspection import permutation_importance\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "from keras.layers import LSTM, Dense\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9l-yE5kdIwS"
      },
      "source": [
        "##Cargar Datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W95aFlIGnShd"
      },
      "outputs": [],
      "source": [
        "dataframe= pd.DataFrame()\n",
        "backup_dataframe = dataframe\n",
        "personas = ['pklS3_BD3','pklS4_BD3','pklS5_BD3','pklS6_BD3','pklS7_BD3','pklS8_BD3','pklS9_BD3','pklS10_BD3','pklS11_BD3','pklS13_BD3','pklS14_BD3','pklS15_BD3','pklS16_BD3','pklS17_BD3'] # Nombres de las bases de datos a usar\n",
        "for i in personas:\n",
        "  filename = '{0}.csv'.format(i)\n",
        "  datos = pd.read_csv(filename,header=None)\n",
        "  datos = datos.transpose()\n",
        "  dataframe = pd.concat([dataframe, datos], axis=0)\n",
        "dataframe= dataframe.reset_index(drop=True)\n",
        "# Usar para BD1:\n",
        "#nombres = ['Area' ,'COHE', 'distPKM', 'HF', 'HR' ,'LF', 'LFHF', 'pNN50', 'Ratiopoinc', 'RMSSD', 'SD1' ,'SD2', 'SDNN', 'TPower','VLF','target','target3']\n",
        "# Usar para BD2:\n",
        "nombres = ['Area' ,'COHE', 'distPKM', 'HF', 'HR' ,'LF', 'LFHF', 'pNN50', 'Ratiopoinc', 'RMSSD', 'SD1' ,'SD2', 'SDNN', 'TPower','VLF','GSRm','SDNNG','maxG','minG','rangoGSR','penGSR','target','target3']\n",
        "# Usar para BD3:\n",
        "#nombres = ['Area' ,'COHE', 'distPKM', 'HF', 'HR' ,'LF', 'LFHF', 'pNN50', 'Ratiopoinc', 'RMSSD', 'SD1' ,'SD2', 'SDNN', 'TPower','VLF','GSRm','SDNNG','maxG','minG','rangoGSR','penGSR','tempm','SDNNt','maxt','mint','RangoT','penT','target','target3']\n",
        "# Usar para BD4:\n",
        "#nombres = ['Area' ,'COHE', 'distPKM', 'HF', 'HR' ,'LF', 'LFHF', 'pNN50', 'Ratiopoinc', 'RMSSD', 'SD1' ,'SD2', 'SDNN', 'TPower','VLF','GSRm','SDNNG','maxG','minG','rangoGSR','penGSR','target','target3']\n",
        "\n",
        "feature_names=nombres[0:-2]\n",
        "dataframe.columns= nombres\n",
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS16USeUijbB"
      },
      "source": [
        "##Normalizar datos "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK_IQ6UTbiQX"
      },
      "outputs": [],
      "source": [
        "for names in nombres[0:-1]:\n",
        "    val = dataframe[str(names)]    \n",
        "    dataframe[str(names)]= (val-val.min())/(val.max()-val.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drMrt882imZp"
      },
      "source": [
        "###Datos normalizados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYkd_Sim0xiH"
      },
      "outputs": [],
      "source": [
        "personas_test = ['pklS2_BD3']  #Sujeto con el cual se validara los algoritmos\n",
        "testeo = pd.DataFrame()\n",
        "for i in personas_test:\n",
        "  filename = '{0}.csv'.format(i)\n",
        "  pTest = pd.read_csv(filename,header=None)\n",
        "  pTest = pTest.transpose()\n",
        "  testeo = pd.concat([testeo, pTest], axis=0)\n",
        "testeo= testeo.reset_index(drop=True)\n",
        "testeo.columns= nombres\n",
        "for names in nombres[0:-1]:\n",
        "    val = testeo[str(names)]\n",
        "    testeo[str(names)]= (val-val.min())/(val.max()-val.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plWmgmmZTQyL"
      },
      "source": [
        "##Datos de entrenamiento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nIWyeZkS9ii"
      },
      "outputs": [],
      "source": [
        "X=dataframe[feature_names]  # Caracteristicas\n",
        "y=dataframe['target3']  # Etiqueta para clasifciacion de 3 clases\n",
        "\n",
        "# Division de los datos para entrenamiento y prueba de manera automatica\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # 80% Entrenamiento y 20% prueba\n",
        "# Conjunto de datos para validar los algoritmos con el sujeto extraido\n",
        "X_out= testeo[feature_names]\n",
        "y_out = testeo['target3']\n",
        "\n",
        "X_train=X_train.reset_index(drop=True)\n",
        "X_test=X_test.reset_index(drop=True)\n",
        "y_train=y_train.reset_index(drop=True)\n",
        "y_test=y_test.reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_lZiMAgQi8W"
      },
      "source": [
        "# Numero de divisiones de datos para validación cruzada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPP-OtP6QgKK"
      },
      "outputs": [],
      "source": [
        "kfold_validacion = KFold(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D40qN7FWQu1Q"
      },
      "source": [
        "#Algoritmos de ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gODwJ2AM5dQQ"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DXbTEqbTOEq"
      },
      "outputs": [],
      "source": [
        "#Hiperparámetros\n",
        "n_estimators=120\n",
        "max_depth=8\n",
        "#Creación del modelo\n",
        "RF = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
        "#Entrenamiento\n",
        "RF.fit(X_train,y_train)\n",
        "#Predicción\n",
        "y_pred=RF.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWaDGYtSTaP2"
      },
      "outputs": [],
      "source": [
        "# Metricas de analisis\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRZmuUsxBi3-"
      },
      "source": [
        "###Caracteristicas mas importantes en RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "are1wHf0Bnaf"
      },
      "outputs": [],
      "source": [
        "feature_imp = pd.Series(RF.feature_importances_,index=feature_names).sort_values(ascending=False)\n",
        "feature_imp\n",
        "imp1= feature_imp\n",
        "%matplotlib inline\n",
        "# Creating a bar plot\n",
        "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
        "# Add labels to your graph\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.title(\"Visualizing Important Features\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DN4A-CmP_DQ"
      },
      "outputs": [],
      "source": [
        "# Reporte de datos RF\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "resultadosRF = pd.DataFrame(report).transpose()\n",
        "resultadosRF['balanced_accuracy'] = metrics.balanced_accuracy_score(y_test,y_pred)\n",
        "resultadosRF['clasificador']= 'RF'\n",
        "resultados = cross_val_score(RF, X, y, cv = kfold_validacion)\n",
        "resultadosRF['Cross Validation']=resultados.mean()\n",
        "car_imp=feature_imp[0:len(resultadosRF.axes[0])]\n",
        "resultadosRF['CAR.IMP']= car_imp.index\n",
        "resultadosRF['n_extimator| maxdepth']= (str(n_estimators) +' | '+ str(max_depth)) \n",
        "resultadosRF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v62J9VRiCv-I"
      },
      "source": [
        "###Matriz de confusión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdIQOquDCu3b"
      },
      "outputs": [],
      "source": [
        "conf_mat = confusion_matrix(y_test, y_pred)\n",
        "print(conf_mat)\n",
        "sns.set(font_scale=2)\n",
        "sns.heatmap(conf_mat, annot=True, annot_kws={\"size\": 16})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VjFXr6UW2c8"
      },
      "source": [
        "##SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm9zBhtSKDo7"
      },
      "outputs": [],
      "source": [
        "# Hiperparámetros SVM rbf\n",
        "gamma= 1\n",
        "C1 = 50\n",
        "# Hiperparámetros SVM polinomial\n",
        "degree=5 \n",
        "C2 = 50\n",
        "# Hiperparámetros SVM lineal\n",
        "C3 = 10\n",
        "rbf_svc = svm.SVC(kernel='rbf', gamma=gamma, C=C1).fit(X_train.values, y_train)\n",
        "poly_svc = svm.SVC(kernel='poly', degree=degree, C=C2).fit(X_train.values, y_train)\n",
        "lin_svc = svm.LinearSVC(C=C3, max_iter=10000).fit(X_train.values, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bcTPRK3l4IC"
      },
      "outputs": [],
      "source": [
        "# Resultados del modelo SVM rbf\n",
        "Z = rbf_svc.predict(np.c_[X_test])\n",
        "conf_mat = confusion_matrix(y_test, Z)\n",
        "print(conf_mat)\n",
        "report = classification_report(y_test, Z, output_dict=True)\n",
        "rbf = pd.DataFrame(report).transpose()\n",
        "rbf['balanced_accuracy'] = metrics.balanced_accuracy_score(y_test,Z)\n",
        "resultados = cross_val_score(rbf_svc, X, y, cv = kfold_validacion)\n",
        "rbf['Cross Validation'] = resultados.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NERVLc5pl64Q"
      },
      "outputs": [],
      "source": [
        "# Resultados del modelo SVM polinomial\n",
        "Z = poly_svc.predict(np.c_[X_test])\n",
        "conf_mat = confusion_matrix(y_test, Z)\n",
        "print(conf_mat)\n",
        "report = classification_report(y_test, Z, output_dict=True)\n",
        "poly = pd.DataFrame(report).transpose()\n",
        "poly['balanced_accuracy'] = metrics.balanced_accuracy_score(y_test,Z)\n",
        "resultados = cross_val_score(poly_svc, X, y, cv = kfold_validacion)\n",
        "poly['Cross Validation'] = resultados.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sl2Y4jqbl7uC"
      },
      "outputs": [],
      "source": [
        "# Resultados del modelo SVM lineal\n",
        "Z = lin_svc.predict(np.c_[X_test])\n",
        "conf_mat = confusion_matrix(y_test, Z)\n",
        "print(conf_mat)\n",
        "report = classification_report(y_test, Z, output_dict=True)\n",
        "lin = pd.DataFrame(report).transpose()\n",
        "lin['balanced_accuracy'] = metrics.balanced_accuracy_score(y_test,Z)\n",
        "resultados = cross_val_score(lin_svc, X, y, cv = kfold_validacion)\n",
        "lin['Cross Validation'] = resultados.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm7ynO8pbjvM"
      },
      "outputs": [],
      "source": [
        "rbf['C | gamma']=str(C1)+' | '+str(gamma)\n",
        "poly['C | degree']= str(C2)+' | '+str(degree)\n",
        "lin['C']= str(C3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G59lDrhtFJ5L"
      },
      "source": [
        "###Caracteristicas mas importantes de SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGBgM49fFNVd"
      },
      "outputs": [],
      "source": [
        "features_svmL=pd.Series(abs(lin_svc.coef_[0]), index=feature_names).sort_values(ascending=False)\n",
        "imp2=features_svmL\n",
        "%matplotlib inline\n",
        "car_imp=features_svmL[0:6]\n",
        "lin['CAR.IMP']= car_imp.index\n",
        "# Creating a bar plot\n",
        "sns.barplot(x=features_svmL, y=features_svmL.index)\n",
        "# Add labels to your graph\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.title(\"Visualizing Important Features\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5-xJPSWPxRs"
      },
      "outputs": [],
      "source": [
        "perm_importance = permutation_importance(rbf_svc, X_test.values, y_test.values)\n",
        "features = np.array(feature_names)\n",
        "sorted_idx = perm_importance.importances_mean.argsort()\n",
        "imp3=features[sorted_idx]\n",
        "imp3=imp3[::-1]\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.barh(features[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
        "plt.xlabel(\"Permutation Importance\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw5k9lJtJMfZ"
      },
      "outputs": [],
      "source": [
        "rbf['CAR.IMP']= features[sorted_idx][::-1][0:6]\n",
        "rbf['CAR.IMP']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0zU8A91VYki"
      },
      "outputs": [],
      "source": [
        "perm_importance = permutation_importance(poly_svc, X_test.values, y_test.values)\n",
        "features = np.array(feature_names)\n",
        "sorted_idx = perm_importance.importances_mean.argsort()\n",
        "imp4=features[sorted_idx]\n",
        "imp4=imp4[::-1]\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.barh(features[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
        "plt.xlabel(\"Permutation Importance\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJQPSBmaS9tq"
      },
      "outputs": [],
      "source": [
        "poly['CAR.IMP']= features[sorted_idx][::-1][0:6]\n",
        "poly['CAR.IMP']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9FceoYvTmmB"
      },
      "outputs": [],
      "source": [
        "resultadosSVM = pd.concat([rbf,poly,lin], axis=0)\n",
        "resultadosSVM['clasificador']= ['rbf','rbf','rbf','rbf','rbf','rbf','poly','poly','poly','poly','poly','poly','linear','linear','linear','linear','linear','linear'] \n",
        "resultadosSVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CqGQ-bHjIJS"
      },
      "source": [
        "##Red Neuronal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PaIUGRiLoAk"
      },
      "source": [
        "###3 clases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHGvSumaboX7"
      },
      "outputs": [],
      "source": [
        "# Clasificación multiclase\n",
        "epochsRN =50\n",
        "neurons = 0 #Neuronas de la capa oculta\n",
        "# definición del modelo\n",
        "def baseline_model(neurons):\n",
        "  # Creación el modelo\n",
        "  model = Sequential()\n",
        "  model.add(Dense(X_train.shape[1], input_dim=X_train.shape[1], activation='relu'))\n",
        "  #model.add(Dense(neurons, activation='relu')) #capa oculta(descomentar si se requiere)\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "estimator = KerasClassifier(build_fn=baseline_model, neurons = neurons,epochs= epochsRN, verbose=0)\n",
        "seed = 5\n",
        "np.random.seed(seed)\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X_train, y_train, cv=kfold)\n",
        "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gT8xqPSK-Y8e"
      },
      "outputs": [],
      "source": [
        "#Entrenamiento de la red\n",
        "estimator.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "oFa1vmXbkGQ5"
      },
      "outputs": [],
      "source": [
        "# Caracteristicas importantes\n",
        "perm = PermutationImportance(estimator, random_state=1).fit(X_train, y_train)\n",
        "impFNN=np.argsort(perm.feature_importances_)\n",
        "features = np.array(feature_names)\n",
        "imp5=features[impFNN][::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hpiudaj1g7Eb"
      },
      "outputs": [],
      "source": [
        "# Resultados RN\n",
        "y_pred = estimator.predict(X_test)\n",
        "report = classification_report(y_test,y_pred, output_dict=True)\n",
        "resultadosRN = pd.DataFrame()\n",
        "resultadosRN = pd.DataFrame(report).transpose()\n",
        "resultadosRN['balanced_accuracy'] = metrics.balanced_accuracy_score(y_test,y_pred)\n",
        "resultadosRN['CAR.IMP']= features[impFNN][::-1][0:6]\n",
        "resultadosRN['epocas'] = str(epochsRN)\n",
        "resultadosRN['clasificador'] = 'RN'\n",
        "resultadosRN['Cross Validation'] = results.mean()\n",
        "resultadosRN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "578vcEsW538q"
      },
      "source": [
        "#Red Neuronal LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "ElZS3dnkjgzv"
      },
      "outputs": [],
      "source": [
        "# Añadir una tercera dimensión a los conjuntos de datos\n",
        "nmp=X_train.to_numpy()\n",
        "Xa = np.reshape(nmp, (len(nmp),1,len(feature_names)))\n",
        "XTa = np.reshape(X_test.values, (len(X_test),1,len(feature_names)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swgufnujWtOb"
      },
      "source": [
        "###3 clases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTpcVbhCpAmR"
      },
      "outputs": [],
      "source": [
        "# Clasificación multiclase\n",
        "epochsLSTM =15\n",
        "# Definición del modelos\n",
        "def LSTM_model():\n",
        "  # Creación el modelo\n",
        "  modelo = Sequential()\n",
        "  modelo.add(LSTM(X_train.shape[1], input_dim=X_train.shape[1], activation='relu'))\n",
        "  modelo.add(Dense(3, activation='softmax'))\n",
        "  modelo.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
        "  return modelo\n",
        "estimatorLSTM = KerasClassifier(build_fn=LSTM_model,epochs= epochsLSTM, verbose=0)\n",
        "seed = 5\n",
        "np.random.seed(seed)\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "resultsLSTM = cross_val_score(estimatorLSTM, Xa, y_train, cv=kfold)\n",
        "print(\"Accuracy: %.2f%% (%.2f%%)\" % (resultsLSTM .mean()*100, resultsLSTM .std()*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6tcgjHzTsZ8"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento de la red LSTM\n",
        "estimatorLSTM.fit(Xa, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAilFoe6g9UZ"
      },
      "outputs": [],
      "source": [
        "# Caracterisitcas importantes\n",
        "CILSTM = []\n",
        "predLSTM= estimatorLSTM.predict(XTa,verbose=0).squeeze()\n",
        "baseline_mae = np.mean(np.abs(predLSTM-y_test))         \n",
        "COLS = list(X_train.columns)\n",
        "for k in tqdm(range(len(COLS))):\n",
        "                \n",
        "  save_col = XTa[:,:,k].copy()\n",
        "  np.random.shuffle(XTa[:,:,k])\n",
        "          \n",
        "  oof_preds = estimatorLSTM.predict(XTa, verbose=0).squeeze() \n",
        "  mae = np.mean(np.abs( oof_preds-y_test ))\n",
        "  CILSTM.append({'feature':COLS[k],'mae':mae})\n",
        "  XTa[:,:,k] = save_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoweBuXnlBx6"
      },
      "outputs": [],
      "source": [
        "print()\n",
        "df = pd.DataFrame(CILSTM)\n",
        "df = df.sort_values('mae',ascending=False)\n",
        "imp6=np.array(df['feature'][0::])\n",
        "plt.figure(figsize=(10,20))\n",
        "plt.barh(np.arange(len(COLS)),df.mae)\n",
        "plt.yticks(np.arange(len(COLS)),df.feature.values)\n",
        "plt.title('LSTM Feature Importance',size=16)\n",
        "plt.ylim((-1,len(COLS)+1))\n",
        "plt.plot([baseline_mae,baseline_mae],[-1,len(COLS)+1], '--', color='orange',\n",
        "          label=f'Baseline OOF\\nMAE={baseline_mae:.3f}')\n",
        "plt.xlabel(f'OOF MAE with feature permuted',size=14)\n",
        "plt.ylabel('Feature',size=14)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdq1iWAMTyxp"
      },
      "outputs": [],
      "source": [
        "#Resultados de red LSTM\n",
        "predLSTM= estimatorLSTM.predict(XTa)\n",
        "report = classification_report(y_test,predLSTM, output_dict=True)\n",
        "resultadosRNLSTM = pd.DataFrame()\n",
        "RNLSTM = pd.DataFrame(report).transpose()\n",
        "RNLSTM['balanced_accuracy'] = metrics.balanced_accuracy_score(y_test,predLSTM)\n",
        "resultadosRNLSTM = resultadosRNLSTM.append(RNLSTM)\n",
        "resultadosRNLSTM['CAR.IMP']= np.array(df['feature'][0:6])\n",
        "resultadosRNLSTM['epocas'] =str(epochsLSTM)\n",
        "resultadosRNLSTM['Cross Validation'] = resultsLSTM.mean()\n",
        "resultadosRNLSTM['clasificador'] = 'LSTM'\n",
        "resultadosRNLSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp8f_wsw_IGN"
      },
      "source": [
        "ADABOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvVVxuMwxoMB"
      },
      "outputs": [],
      "source": [
        "ydf = pd.DataFrame(y_train)\n",
        "ytestdf = pd.DataFrame(y_test)\n",
        "# Hiperparámetros\n",
        "n_estimator= 70\n",
        "learning_rate= 0.1\n",
        "\n",
        "AB = AdaBoostClassifier(n_estimators=n_estimator, learning_rate= learning_rate)\n",
        "AB.fit(X_train, y_train)\n",
        "y_predAB=AB.predict(X_test)\n",
        "\n",
        "if max(y_test)==2:\n",
        "  xad = X_train.drop(ydf[ydf['target3']==0].index)\n",
        "  yad =y_train.drop(ydf[ydf['target3']==0].index) \n",
        "  AB2 = AdaBoostClassifier(n_estimators=n_estimator, learning_rate= learning_rate)\n",
        "  AB2.fit(xad, yad)\n",
        "\n",
        "  for i in range(0,len(y_predAB),1):\n",
        "    if y_predAB[i]==1:\n",
        "      y_predAB[i] = AB2.predict(X_test.loc[[i]])\n",
        "\n",
        "print(classification_report(y_test, y_predAB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LNX4kvIV5bX"
      },
      "outputs": [],
      "source": [
        "# Caracteristicas importantes\n",
        "feature_impAB = pd.Series(AB.feature_importances_,index=feature_names).sort_values(ascending=False)\n",
        "feature_impAB\n",
        "imp7=feature_impAB\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "sns.barplot(x=feature_impAB, y=feature_impAB.index)\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.title(\"Visualizing Important Features\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfcxBLt_HpFF"
      },
      "outputs": [],
      "source": [
        "# Resultados AB\n",
        "report = classification_report(y_test,y_predAB, output_dict=True)\n",
        "resultadosAB = pd.DataFrame()\n",
        "rAB = pd.DataFrame(report).transpose()\n",
        "resultadosAB = resultadosAB.append(rAB)\n",
        "resultadosAB['balanced_accuracy'] = metrics.balanced_accuracy_score(y_test,y_predAB)\n",
        "resultadosAB['n_est | learning rate']= str(n_estimator)+' | '+str(learning_rate)\n",
        "resultadosAB['clasificador']='AB'\n",
        "resultados = cross_val_score(AB, X, y, cv = kfold_validacion)\n",
        "resultadosAB['Cross Validation'] = resultados.mean()\n",
        "car_imp=feature_impAB[0:len(resultadosAB.axes[0])]\n",
        "resultadosAB['CAR.IMP']= car_imp.index\n",
        "resultadosAB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft8uN1Kzbjqi"
      },
      "source": [
        "### Concatenación de los resultados de los algoritmos con la división de datos 80% - 20%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_Udiv-wI2Dx"
      },
      "outputs": [],
      "source": [
        "resul = pd.concat([resultadosRF, resultadosSVM, resultadosRN,resultadosRNLSTM, resultadosAB], axis=0)\n",
        "resul.fillna('-')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15ZdjtdLbUR-"
      },
      "source": [
        "### Validación con el sujeto extraido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zz24Hkc5kYjm"
      },
      "outputs": [],
      "source": [
        "#RF\n",
        "y_pred=RF.predict(X_out)\n",
        "report = classification_report(y_out, y_pred, output_dict=True)\n",
        "resultadosRF2 = pd.DataFrame(report).transpose()\n",
        "resultadosRF2['balanced_accuracy*'] = metrics.balanced_accuracy_score(y_out,y_pred)\n",
        "\n",
        "#SVM rbf\n",
        "Z = rbf_svc.predict(np.c_[X_out])\n",
        "conf_mat = confusion_matrix(y_out, Z)\n",
        "print(conf_mat)\n",
        "report = classification_report(y_out, Z, output_dict=True)\n",
        "rbf2 = pd.DataFrame(report).transpose()\n",
        "rbf2['balanced_accuracy*'] = metrics.balanced_accuracy_score(y_out,Z)\n",
        "\n",
        "#SVM polinomial\n",
        "Z = poly_svc.predict(np.c_[X_out])\n",
        "conf_mat = confusion_matrix(y_out, Z)\n",
        "print(conf_mat)\n",
        "report = classification_report(y_out, Z, output_dict=True)\n",
        "poly2 = pd.DataFrame(report).transpose()\n",
        "poly2['balanced_accuracy*'] = metrics.balanced_accuracy_score(y_out,Z)\n",
        "\n",
        "#SVM lineal\n",
        "Z = lin_svc.predict(np.c_[X_out])\n",
        "conf_mat = confusion_matrix(y_out, Z)\n",
        "print(conf_mat)\n",
        "report = classification_report(y_out, Z, output_dict=True)\n",
        "lin2 = pd.DataFrame(report).transpose()\n",
        "lin2['balanced_accuracy*'] = metrics.balanced_accuracy_score(y_out,Z)\n",
        "\n",
        "resultadosSVM2 = pd.concat([rbf2,poly2,lin2], axis=0)\n",
        "\n",
        "#RN\n",
        "y_pr= estimator.predict(X_out)\n",
        "report = classification_report(y_out,y_pr, output_dict=True)\n",
        "resultadosRN2 = pd.DataFrame()\n",
        "RNeuronal2 = pd.DataFrame(report).transpose()\n",
        "RNeuronal2['balanced_accuracy*'] = metrics.balanced_accuracy_score(y_out,y_pr)\n",
        "resultadosRN2 = resultadosRN2.append(RNeuronal2)\n",
        "\n",
        "#LSTM\n",
        "XTa = np.reshape(X_out.values, (len(X_out),1,len(feature_names)))\n",
        "predLSTM= estimatorLSTM.predict(XTa)\n",
        "report = classification_report(y_out,predLSTM, output_dict=True)\n",
        "resultadosRNLSTM2 = pd.DataFrame()\n",
        "RNLSTM2 = pd.DataFrame(report).transpose()\n",
        "RNLSTM2['balanced_accuracy*'] = metrics.balanced_accuracy_score(y_out,predLSTM)\n",
        "resultadosRNLSTM2 = resultadosRNLSTM2.append(RNLSTM2)\n",
        "\n",
        "#AB\n",
        "y_predAB=AB.predict(X_out)\n",
        "\n",
        "if max(y_out)==2:\n",
        "  xad = X.drop(ydf[ydf['target3']==0].index)\n",
        "  yad =y.drop(ydf[ydf['target3']==0].index) \n",
        "  AB2 = AdaBoostClassifier(n_estimators=n_estimator, learning_rate= learning_rate)\n",
        "  AB2.fit(xad, yad)\n",
        " \n",
        "  for i in range(0,len(y_predAB)-1,1):\n",
        "    if y_predAB[i]==1:\n",
        "       y_predAB[i] = AB2.predict(X_out.loc[[i]])\n",
        "    \n",
        "  \n",
        "report = classification_report(y_out,y_predAB, output_dict=True)\n",
        "resultadosAB2 = pd.DataFrame()\n",
        "rAB = pd.DataFrame(report).transpose()\n",
        "resultadosAB2 = resultadosAB2.append(rAB)\n",
        "    #resultadosSVM = resultadosSVM()\n",
        "resultadosAB2['balanced_accuracy*'] = metrics.balanced_accuracy_score(y_out,y_predAB)\n",
        "resultadosAB2[''] = ''\n",
        "\n",
        "# Concatenación de los resultados de los algoritmos al validar con el sujeto extraido\n",
        "result = pd.concat([resultadosRF2, resultadosSVM2, resultadosRN2,resultadosRNLSTM2, resultadosAB2], axis=0)\n",
        "result.fillna('-')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VFwA0SulwAt"
      },
      "source": [
        "## Procedimiento de extracción de resultados con las caracteristicas mas importantes extraidas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "AU2EnQXL3Dnq"
      },
      "outputs": [],
      "source": [
        "numeroCarImp=10 #Numero de caracteristicas mas relevantes con las cuales se va a entrenar\n",
        "dfimp1=pd.DataFrame(imp1[0:numeroCarImp]).reset_index().rename(columns={'index':'Carac'})\n",
        "dfimp2=pd.DataFrame(imp2[0:numeroCarImp]).reset_index().rename(columns={'index':'Carac'})\n",
        "dfimp3=pd.DataFrame(imp3[0:numeroCarImp],columns=['Carac'])\n",
        "dfimp4=pd.DataFrame(imp4[0:numeroCarImp],columns=['Carac'])\n",
        "dfimp5=pd.DataFrame(imp5[0:numeroCarImp],columns=['Carac'])\n",
        "dfimp6=pd.DataFrame(imp6[0:numeroCarImp],columns=['Carac'])\n",
        "dfimp7=pd.DataFrame(imp7[0:numeroCarImp]).reset_index().rename(columns={'index':'Carac'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcMNKPMJckRO"
      },
      "source": [
        "### Lista de caracteristica más relevantes en orden de importancia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGSZ7uTB3abC"
      },
      "outputs": [],
      "source": [
        "dfCarImp=pd.DataFrame(pd.concat([dfimp1['Carac'],dfimp2['Carac'],dfimp3['Carac'],dfimp4['Carac'],dfimp5['Carac'],dfimp6['Carac'],dfimp7['Carac']],axis=0))\n",
        "resultadosCar = dfCarImp.value_counts().reset_index()\n",
        "CaracCo=list(resultadosCar['Carac'][0:numeroCarImp])\n",
        "CaracCo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "LAQq_jyEniEE"
      },
      "outputs": [],
      "source": [
        "# Creación de los nuevos conjuntos de entrenamiento con las caracteristicas mas importantes\n",
        "X_train2=X_train[CaracCo].copy()\n",
        "X_out2=X_out[CaracCo].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5bloE1pd-IW"
      },
      "source": [
        "Entrenamiento y validación de los algoritmos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL7vV9yNlvi1"
      },
      "outputs": [],
      "source": [
        "#RF\n",
        "RF = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
        "RF.fit(X_train2,y_train)\n",
        "y_pred=RF.predict(X_out2)\n",
        "report = classification_report(y_out, y_pred, output_dict=True)\n",
        "resultadosRF3 = pd.DataFrame(report).transpose()\n",
        "resultadosRF3['balanced_accuracy**'] = metrics.balanced_accuracy_score(y_out,y_pred)\n",
        "\n",
        "#SVM \n",
        "rbf_svc = svm.SVC(kernel='rbf', gamma=gamma, C=C1).fit(X_train2.values, y_train)\n",
        "poly_svc = svm.SVC(kernel='poly', degree=degree, C=C2).fit(X_train2.values, y_train)\n",
        "lin_svc = svm.LinearSVC(C=C3, max_iter=10000).fit(X_train2.values, y_train)\n",
        "\n",
        "#SVM rbf\n",
        "Z = rbf_svc.predict(np.c_[X_out2])\n",
        "conf_mat = confusion_matrix(y_out, Z)\n",
        "print(conf_mat)\n",
        "report = classification_report(y_out, Z, output_dict=True)\n",
        "rbf3 = pd.DataFrame(report).transpose()\n",
        "rbf3['balanced_accuracy**'] = metrics.balanced_accuracy_score(y_out,Z)\n",
        "\n",
        "#SVM polinomial\n",
        "Z = poly_svc.predict(np.c_[X_out2])\n",
        "conf_mat = confusion_matrix(y_out, Z)\n",
        "print(conf_mat)\n",
        "report = classification_report(y_out, Z, output_dict=True)\n",
        "poly3 = pd.DataFrame(report).transpose()\n",
        "poly3['balanced_accuracy**'] = metrics.balanced_accuracy_score(y_out,Z)\n",
        "\n",
        "#SVM lineal\n",
        "Z = lin_svc.predict(np.c_[X_out2])\n",
        "conf_mat = confusion_matrix(y_out, Z)\n",
        "print(conf_mat)\n",
        "report = classification_report(y_out, Z, output_dict=True)\n",
        "lin3 = pd.DataFrame(report).transpose()\n",
        "lin3['balanced_accuracy**'] = metrics.balanced_accuracy_score(y_out,Z)\n",
        "\n",
        "resultadosSVM3 = pd.concat([rbf3,poly3,lin3], axis=0)\n",
        "\n",
        "#RN\n",
        "def baseline_model(neurons):\n",
        "  # crea el modelo\n",
        "  model = Sequential()\n",
        "  model.add(Dense(X_train2.shape[1], input_dim=X_train2.shape[1], activation='relu'))\n",
        "  #model.add(Dense(neurons, activation='relu'))\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "  # Compile el modelo\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "estimator = KerasClassifier(build_fn=baseline_model, neurons = neurons,epochs= epochsRN, verbose=0)\n",
        "estimator.fit(X_train2, y_train)\n",
        "y_pr= estimator.predict(X_out2)\n",
        "report = classification_report(y_out,y_pr, output_dict=True)\n",
        "resultadosRN3 = pd.DataFrame()\n",
        "RNeuronal3 = pd.DataFrame(report).transpose()\n",
        "RNeuronal3['balanced_accuracy**'] = metrics.balanced_accuracy_score(y_out,y_pr)\n",
        "resultadosRN3 = resultadosRN3.append(RNeuronal3)\n",
        "\n",
        "#LSTM\n",
        "nmp=X_train2.to_numpy()\n",
        "Xa = np.reshape(nmp, (len(nmp),1,numeroCarImp))\n",
        "XTa = np.reshape(X_out2.values, (len(X_out2),1,numeroCarImp))\n",
        "def LSTM_model():\n",
        "  # crea el modelo\n",
        "  modelo = Sequential()\n",
        "  modelo.add(LSTM(X_train2.shape[1], input_dim=X_train2.shape[1], activation='relu'))\n",
        "  modelo.add(Dense(3, activation='softmax'))\n",
        "  modelo.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
        "  # Compile el modelo\n",
        "  return modelo\n",
        "estimatorLSTM = KerasClassifier(build_fn=LSTM_model,epochs= epochsLSTM, verbose=0)\n",
        "estimatorLSTM.fit(Xa, y_train)\n",
        "predLSTM= estimatorLSTM.predict(XTa)\n",
        "report = classification_report(y_out,predLSTM, output_dict=True)\n",
        "resultadosRNLSTM3 = pd.DataFrame()\n",
        "RNLSTM3 = pd.DataFrame(report).transpose()\n",
        "RNLSTM3['balanced_accuracy**'] = metrics.balanced_accuracy_score(y_out,predLSTM)\n",
        "resultadosRNLSTM3 = resultadosRNLSTM3.append(RNLSTM3)\n",
        "\n",
        "#AB\n",
        "\n",
        "AB = AdaBoostClassifier(n_estimators=n_estimator, learning_rate= learning_rate)\n",
        "AB.fit(X_train2, y_train)\n",
        "\n",
        "y_predAB=AB.predict(X_out2)\n",
        "\n",
        "if max(y_out)==2:\n",
        "  xad = X_train2.drop(ydf[ydf['target3']==0].index)\n",
        "  yad =y_train.drop(ydf[ydf['target3']==0].index) \n",
        "  AB2 = AdaBoostClassifier(n_estimators=n_estimator, learning_rate= learning_rate)\n",
        "  AB2.fit(xad, yad)\n",
        "\n",
        " \n",
        "  for i in range(0,len(y_predAB)-1,1):\n",
        "    if y_predAB[i]==1:\n",
        "       y_predAB[i] = AB2.predict(X_out2.loc[[i]])\n",
        "    \n",
        "report = classification_report(y_out,y_predAB, output_dict=True)\n",
        "resultadosAB3 = pd.DataFrame()\n",
        "rAB = pd.DataFrame(report).transpose()\n",
        "resultadosAB3 = resultadosAB3.append(rAB)\n",
        "resultadosAB3['balanced_accuracy**'] = metrics.balanced_accuracy_score(y_out,y_predAB)\n",
        "\n",
        "# Concatenación de los resultados de los algoritmos al validar con el sujeto extraido y caracteristicas reducidas\n",
        "result2 = pd.concat([resultadosRF3, resultadosSVM3, resultadosRN3,resultadosRNLSTM3, resultadosAB3], axis=0)\n",
        "result2.fillna('-')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOi5bgiTefyV"
      },
      "source": [
        "##Unión de todos los resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ex_HGLjrnybr"
      },
      "outputs": [],
      "source": [
        "Final_res = pd.concat([resul,result,result2], axis=1)\n",
        "Final_res.fillna('-')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjjwjQcqGEEz"
      },
      "source": [
        "# Guardar archivo de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "yNQIuqp4ke9V"
      },
      "outputs": [],
      "source": [
        "Final_res.to_excel(str(personas_test)[5:-1]+'_C='+str(numeroCarImp)+'_tri.xlsx')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "v62J9VRiCv-I"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}